{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN, PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from deterioration_model import bridgedeterioration\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)  # or logging.INFO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize environment and vectorize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = bridgedeterioration(df_path='bridge_data.csv')\n",
    "\n",
    "# Wrap the environment with DummyVecEnv\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Normalize the observations (Improves stability while training)\n",
    "norm_env = VecNormalize(env, norm_obs=True, norm_reward= False, clip_obs= float('inf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training based on simple PPO algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 139          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 146          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037288873 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -26.8        |\n",
      "|    explained_variance   | 0.715        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.29e+05     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0154      |\n",
      "|    value_loss           | 3.08e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 135          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 302          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045233862 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -26.8        |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.07e+03     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.0201      |\n",
      "|    value_loss           | 5.33e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 134         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 457         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008573426 |\n",
      "|    clip_fraction        | 0.0454      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.7       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.59e+03    |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0248     |\n",
      "|    value_loss           | 8.21e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 131         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 623         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010155702 |\n",
      "|    clip_fraction        | 0.075       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -26.4       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.66e+03    |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0285     |\n",
      "|    value_loss           | 4.78e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x25b9c582490>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_kwargs = dict(activation_fn=th.nn.ReLU, net_arch=[128, 128])\n",
    "norm_env.reset()\n",
    "model = PPO(\"MlpPolicy\", norm_env, n_epochs = 10, learning_rate=0.0003, batch_size = 64, ent_coef=0.01, gamma = 0.99, policy_kwargs= policy_kwargs,verbose=2)\n",
    "model.learn(total_timesteps=100000, log_interval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To perform 50 steps and check the actions taken by the model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1, Action: [3 1 1 2 2 5 4 3 2 1 2 2 3 0 1]\n",
      "\t Failure Probabilities: [0.0926 0.0159 0.0299 0.1754 0.1361 0.0002 0.2864 0.0002 0.0564 0.3945 0.1553 0.1963 0.5605 0.346  0.0017]\n",
      "Step: 2, Action: [0 1 1 2 2 0 4 2 1 1 2 2 3 0 1]\n",
      "\t Failure Probabilities: [0.1007 0.0201 0.0355 0.024  0.0098 0.0008 0.0002 0.0002 0.063  0.4067 0.0161 0.0333 0.1092 0.3581 0.0039]\n",
      "Step: 3, Action: [0 1 2 0 2 0 4 2 1 1 2 2 3 0 1]\n",
      "\t Failure Probabilities: [0.1092 0.0248 0.0003 0.0285 0.0002 0.0018 0.0002 0.0002 0.0699 0.4188 0.0002 0.0002 0.0002 0.3702 0.0069]\n",
      "Step: 4, Action: [0 1 2 0 2 0 4 2 1 1 2 2 3 0 2]\n",
      "\t Failure Probabilities: [0.1179 0.0299 0.0003 0.0333 0.0002 0.0032 0.0002 0.0002 0.0771 0.4309 0.0002 0.0002 0.0002 0.3824 0.0004]\n",
      "Step: 5, Action: [0 1 2 0 2 0 4 2 1 1 2 2 3 0 2]\n",
      "\t Failure Probabilities: [0.1269 0.0355 0.0003 0.0386 0.0002 0.005  0.0002 0.0002 0.0847 0.443  0.0002 0.0002 0.0002 0.3945 0.0004]\n",
      "Step: 6, Action: [0 1 2 0 2 0 4 2 1 1 2 2 3 0 2]\n",
      "\t Failure Probabilities: [0.1361 0.0415 0.0003 0.0442 0.0002 0.0072 0.0002 0.0002 0.0926 0.4551 0.0002 0.0002 0.0002 0.4067 0.0004]\n",
      "Step: 7, Action: [0 1 2 0 2 0 2 2 1 1 2 2 3 0 2]\n",
      "\t Failure Probabilities: [0.1456 0.0479 0.0003 0.0501 0.0002 0.0098 0.0002 0.0002 0.1007 0.4671 0.0002 0.0002 0.0002 0.4188 0.0004]\n",
      "Step: 8, Action: [0 1 2 0 2 0 2 2 1 1 2 2 3 0 2]\n",
      "\t Failure Probabilities: [0.1553 0.0548 0.0003 0.0564 0.0002 0.0128 0.0002 0.0002 0.1092 0.479  0.0002 0.0002 0.0002 0.4309 0.0004]\n",
      "Step: 9, Action: [0 1 1 0 2 0 2 2 1 1 2 2 3 0 2]\n",
      "\t Failure Probabilities: [0.1653 0.0622 0.001  0.063  0.0002 0.0161 0.0002 0.0002 0.1179 0.4909 0.0002 0.0002 0.0002 0.443  0.0004]\n",
      "Step: 10, Action: [0 1 1 0 2 0 2 2 1 1 2 2 3 0 2]\n",
      "\t Failure Probabilities: [0.1754 0.0699 0.0023 0.0699 0.0002 0.0199 0.0002 0.0002 0.1269 0.5027 0.0002 0.0002 0.0002 0.4551 0.0004]\n",
      "Step: 11, Action: [0 1 1 0 2 0 2 2 1 1 2 2 3 0 2]\n",
      "\t Failure Probabilities: [0.1858 0.078  0.004  0.0771 0.0002 0.024  0.0002 0.0002 0.1361 0.5145 0.0002 0.0002 0.0002 0.4671 0.0004]\n",
      "Step: 12, Action: [0 1 1 0 2 0 2 2 1 1 2 2 3 0 2]\n",
      "\t Failure Probabilities: [0.1963 0.0865 0.0062 0.0847 0.0002 0.0285 0.0002 0.0002 0.1456 0.5261 0.0002 0.0002 0.0002 0.479  0.0004]\n",
      "Step: 13, Action: [0 1 1 0 2 0 2 2 1 1 2 2 3 0 2]\n",
      "\t Failure Probabilities: [0.2071 0.0954 0.009  0.0926 0.0002 0.0333 0.0002 0.0002 0.1553 0.5377 0.0002 0.0002 0.0002 0.4909 0.0004]\n",
      "Step: 14, Action: [0 1 1 0 2 0 2 2 1 1 2 2 3 0 2]\n",
      "\t Failure Probabilities: [0.218  0.1047 0.0122 0.1007 0.0002 0.0386 0.0002 0.0002 0.1653 0.5491 0.0002 0.0002 0.0002 0.5027 0.0004]\n",
      "Step: 15, Action: [0 1 1 0 2 0 2 2 1 1 2 2 3 0 2]\n",
      "\t Failure Probabilities: [0.229  0.1143 0.0159 0.1092 0.0002 0.0442 0.0002 0.0002 0.1754 0.5605 0.0002 0.0002 0.0002 0.5145 0.0004]\n",
      "Step: 16, Action: [0 1 1 0 2 0 2 2 1 1 2 2 3 0 2]\n",
      "\t Failure Probabilities: [0.2402 0.1242 0.0201 0.1179 0.0002 0.0501 0.0002 0.0002 0.1858 0.5717 0.0002 0.0002 0.0002 0.5261 0.0004]\n",
      "Step: 17, Action: [0 1 1 0 2 0 2 2 1 1 2 2 3 0 2]\n",
      "\t Failure Probabilities: [0.2516 0.1345 0.0248 0.1269 0.0002 0.0564 0.0002 0.0002 0.1963 0.5828 0.0002 0.0002 0.0002 0.5377 0.0004]\n",
      "Step: 18, Action: [0 1 1 0 2 0 2 2 1 1 2 2 3 0 2]\n",
      "\t Failure Probabilities: [0.2631 0.145  0.0299 0.1361 0.0002 0.063  0.0002 0.0002 0.2071 0.5938 0.0002 0.0002 0.0002 0.5491 0.0004]\n",
      "Step: 19, Action: [0 1 1 0 2 0 2 2 1 1 2 2 3 0 2]\n",
      "\t Failure Probabilities: [0.2747 0.1559 0.0355 0.1456 0.0002 0.0699 0.0002 0.0002 0.218  0.6047 0.0002 0.0002 0.0002 0.5605 0.0004]\n",
      "Step: 20, Action: [0 1 1 0 2 0 2 2 1 1 2 2 2 0 2]\n",
      "\t Failure Probabilities: [0.2864 0.167  0.0415 0.1553 0.0002 0.0771 0.0002 0.0002 0.229  0.6154 0.0002 0.0002 0.0002 0.5717 0.0004]\n",
      "Step: 21, Action: [0 1 1 0 2 0 2 2 1 1 2 2 2 0 2]\n",
      "\t Failure Probabilities: [0.2981 0.1784 0.0479 0.1653 0.0002 0.0847 0.0002 0.0002 0.2402 0.626  0.0002 0.0002 0.0002 0.5828 0.0004]\n",
      "Step: 22, Action: [0 1 1 0 2 0 2 2 1 1 2 2 2 0 2]\n",
      "\t Failure Probabilities: [0.31   0.1901 0.0548 0.1754 0.0002 0.0926 0.0002 0.0002 0.2516 0.6364 0.0002 0.0002 0.0002 0.5938 0.0004]\n",
      "Step: 23, Action: [0 1 1 0 2 0 2 2 1 1 2 2 2 0 2]\n",
      "\t Failure Probabilities: [0.322  0.202  0.0622 0.1858 0.0002 0.1007 0.0002 0.0002 0.2631 0.6467 0.0002 0.0002 0.0002 0.6047 0.0004]\n",
      "Step: 24, Action: [0 1 1 0 2 0 2 2 1 1 2 2 2 0 2]\n",
      "\t Failure Probabilities: [0.334  0.2141 0.0699 0.1963 0.0002 0.1092 0.0002 0.0002 0.2747 0.6568 0.0002 0.0002 0.0002 0.6154 0.0004]\n",
      "Step: 25, Action: [0 1 1 0 2 0 2 2 1 1 2 2 2 0 2]\n",
      "\t Failure Probabilities: [0.346  0.2264 0.078  0.2071 0.0002 0.1179 0.0002 0.0002 0.2864 0.6668 0.0002 0.0002 0.0002 0.626  0.0004]\n",
      "Step: 26, Action: [0 1 1 0 2 0 0 2 1 1 2 2 2 0 2]\n",
      "\t Failure Probabilities: [0.3581 0.2389 0.0865 0.218  0.0002 0.1269 0.0008 0.0002 0.2981 0.6766 0.0002 0.0002 0.0002 0.6364 0.0004]\n",
      "Step: 27, Action: [0 1 1 0 2 0 0 2 1 1 2 2 2 0 2]\n",
      "\t Failure Probabilities: [0.3702 0.2516 0.0954 0.229  0.0002 0.1361 0.0018 0.0002 0.31   0.6863 0.0002 0.0002 0.0002 0.6467 0.0004]\n",
      "Step: 28, Action: [0 1 1 0 2 0 0 2 1 1 2 2 2 0 2]\n",
      "\t Failure Probabilities: [0.3824 0.2644 0.1047 0.2402 0.0002 0.1456 0.0032 0.0002 0.322  0.6958 0.0002 0.0002 0.0002 0.6568 0.0004]\n",
      "Step: 29, Action: [0 1 1 0 2 0 0 2 1 1 2 2 2 0 2]\n",
      "\t Failure Probabilities: [0.3945 0.2774 0.1143 0.2516 0.0002 0.1553 0.005  0.0002 0.334  0.7051 0.0002 0.0002 0.0002 0.6668 0.0004]\n",
      "Step: 30, Action: [0 1 1 0 2 0 0 2 1 1 2 2 2 0 2]\n",
      "\t Failure Probabilities: [0.4067 0.2905 0.1242 0.2631 0.0002 0.1653 0.0072 0.0002 0.346  0.7142 0.0002 0.0002 0.0002 0.6766 0.0004]\n",
      "Step: 31, Action: [0 1 1 0 2 0 0 2 1 1 2 2 2 0 2]\n",
      "\t Failure Probabilities: [0.4188 0.3037 0.1345 0.2747 0.0002 0.1754 0.0098 0.0002 0.3581 0.7232 0.0002 0.0002 0.0002 0.6863 0.0004]\n",
      "Step: 32, Action: [0 1 1 0 2 0 0 2 1 1 2 2 2 0 2]\n",
      "\t Failure Probabilities: [0.4309 0.317  0.145  0.2864 0.0002 0.1858 0.0128 0.0002 0.3702 0.732  0.0002 0.0002 0.0002 0.6958 0.0004]\n",
      "Step: 33, Action: [0 1 1 0 2 0 0 2 1 1 2 2 2 0 2]\n",
      "\t Failure Probabilities: [0.443  0.3304 0.1559 0.2981 0.0002 0.1963 0.0161 0.0002 0.3824 0.7406 0.0002 0.0002 0.0002 0.7051 0.0004]\n",
      "Step: 34, Action: [0 1 1 0 2 0 0 2 1 1 2 2 2 0 2]\n",
      "\t Failure Probabilities: [0.4551 0.3439 0.167  0.31   0.0002 0.2071 0.0199 0.0002 0.3945 0.7491 0.0002 0.0002 0.0002 0.7142 0.0004]\n",
      "Step: 35, Action: [0 1 1 0 2 0 0 2 1 1 2 2 2 0 2]\n",
      "\t Failure Probabilities: [0.4671 0.3574 0.1784 0.322  0.0002 0.218  0.024  0.0002 0.4067 0.7573 0.0002 0.0002 0.0002 0.7232 0.0004]\n",
      "Step: 36, Action: [0 1 1 0 2 0 0 2 1 1 2 2 2 0 2]\n",
      "\t Failure Probabilities: [0.479  0.3709 0.1901 0.334  0.0002 0.229  0.0285 0.0002 0.4188 0.7654 0.0002 0.0002 0.0002 0.732  0.0004]\n",
      "Step: 37, Action: [0 1 1 0 2 0 0 2 1 1 2 2 2 0 2]\n",
      "\t Failure Probabilities: [0.4909 0.3845 0.202  0.346  0.0002 0.2402 0.0333 0.0002 0.4309 0.7733 0.0002 0.0002 0.0002 0.7406 0.0004]\n",
      "Step: 38, Action: [0 1 1 0 2 0 0 2 1 1 2 0 2 0 2]\n",
      "\t Failure Probabilities: [0.5027 0.3981 0.2141 0.3581 0.0002 0.2516 0.0386 0.0002 0.443  0.7811 0.0002 0.0008 0.0002 0.7491 0.0004]\n",
      "Step: 39, Action: [0 1 1 0 2 0 0 2 1 1 2 0 2 0 2]\n",
      "\t Failure Probabilities: [0.5145 0.4117 0.2264 0.3702 0.0002 0.2631 0.0442 0.0002 0.4551 0.7886 0.0002 0.0018 0.0002 0.7573 0.0004]\n",
      "Step: 40, Action: [0 1 1 1 2 0 0 2 1 1 2 0 2 0 1]\n",
      "\t Failure Probabilities: [0.5261 0.4252 0.2389 0.3824 0.0002 0.2747 0.0501 0.0002 0.4671 0.796  0.0002 0.0032 0.0002 0.7654 0.0017]\n",
      "Step: 41, Action: [0 1 1 1 2 0 0 2 1 1 2 0 2 0 1]\n",
      "\t Failure Probabilities: [0.5377 0.4388 0.2516 0.3945 0.0002 0.2864 0.0564 0.0002 0.479  0.8032 0.0002 0.005  0.0002 0.7733 0.0039]\n",
      "Step: 42, Action: [0 1 1 1 2 0 0 2 1 1 0 0 2 0 1]\n",
      "\t Failure Probabilities: [0.5491 0.4522 0.2644 0.4067 0.0002 0.2981 0.063  0.0002 0.4909 0.8102 0.0008 0.0072 0.0002 0.7811 0.0069]\n",
      "Step: 43, Action: [0 1 1 1 2 0 0 2 1 1 0 0 2 0 1]\n",
      "\t Failure Probabilities: [0.5605 0.4657 0.2774 0.4188 0.0002 0.31   0.0699 0.0002 0.5027 0.8171 0.0018 0.0098 0.0002 0.7886 0.0108]\n",
      "Step: 44, Action: [0 1 1 1 2 0 0 2 1 1 0 0 2 0 1]\n",
      "\t Failure Probabilities: [0.5717 0.479  0.2905 0.4309 0.0002 0.322  0.0771 0.0002 0.5145 0.8237 0.0032 0.0128 0.0002 0.796  0.0155]\n",
      "Step: 45, Action: [0 1 1 1 2 0 0 2 1 1 0 0 2 0 1]\n",
      "\t Failure Probabilities: [0.5828 0.4923 0.3037 0.443  0.0002 0.334  0.0847 0.0002 0.5261 0.8302 0.005  0.0161 0.0002 0.8032 0.021 ]\n",
      "Step: 46, Action: [0 1 1 1 2 0 0 2 1 1 0 0 2 0 1]\n",
      "\t Failure Probabilities: [0.5938 0.5055 0.317  0.4551 0.0002 0.346  0.0926 0.0002 0.5377 0.8366 0.0072 0.0199 0.0002 0.8102 0.0274]\n",
      "Step: 47, Action: [0 1 1 1 2 0 0 2 1 1 0 0 2 0 1]\n",
      "\t Failure Probabilities: [0.6047 0.5186 0.3304 0.4671 0.0002 0.3581 0.1007 0.0002 0.5491 0.8427 0.0098 0.024  0.0002 0.8171 0.0345]\n",
      "Step: 48, Action: [0 1 1 1 2 0 0 2 1 1 0 0 2 0 1]\n",
      "\t Failure Probabilities: [0.6154 0.5316 0.3439 0.479  0.0002 0.3702 0.1092 0.0002 0.5605 0.8487 0.0128 0.0285 0.0002 0.8237 0.0425]\n",
      "Step: 49, Action: [0 1 1 0 2 0 0 2 1 1 0 0 2 0 1]\n",
      "\t Failure Probabilities: [0.626  0.5444 0.3574 0.4909 0.0002 0.3824 0.1179 0.0002 0.5717 0.8545 0.0161 0.0333 0.0002 0.8302 0.0512]\n",
      "Step: 50, Action: [0 1 1 0 2 0 0 2 1 1 0 0 2 0 1]\n",
      "\t Failure Probabilities: [0.6364 0.5571 0.3709 0.5027 0.0002 0.3945 0.1269 0.0002 0.5828 0.8601 0.0199 0.0386 0.0002 0.8366 0.0606]\n"
     ]
    }
   ],
   "source": [
    "norm_env.training = False\n",
    "obs = norm_env.reset()\n",
    "\n",
    "# Get the maximum steps from the underlying environment instance\n",
    "# Assumes only one environment in the VecEnv\n",
    "max_steps = 50\n",
    "num_bridges = norm_env.envs[0].num_bridges\n",
    "\n",
    "steps = 0\n",
    "done = np.array([False]) # Initialize done flag for the VecEnv\n",
    "\n",
    "fp_history = []\n",
    "\n",
    "while not done.all() and steps < max_steps:\n",
    "    # Get action from the model using deterministic prediction for evaluation\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "\n",
    "    print(f\"Step: {steps + 1}, Action: {action[0]}\")\n",
    "\n",
    "    # Take the action in the environment\n",
    "    obs, reward, done, info = norm_env.step(action)\n",
    "\n",
    "    unnormalized_state = info[0]['state']\n",
    "    failure_probs = unnormalized_state[:, 5]\n",
    "    fp_history.append(failure_probs.copy()) # Store if needed\n",
    "\n",
    "    # Format for better readability\n",
    "    fp_str = np.array2string(failure_probs, precision=4, suppress_small=True, max_line_width=120)\n",
    "    print(f\"\\t Failure Probabilities: {fp_str}\")\n",
    "\n",
    "    steps += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feel free to change the reward model to account for different condition and save the model for later use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rllib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
